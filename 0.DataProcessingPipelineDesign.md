# 데이터 처리 파이프라인 설계

## 서비스 개요
여러 채널에서 올라오는 트럼프의 발언을 실시간으로 수집하고, 한국 경제/시장에 미치는 영향을 분석하여 일반 투자자들에게 신속하게 정보를 제공하는 서비스

---

## 핵심 레이어 구조

### 1. 데이터 수집 레이어 (Data Collection Layer)
**역할**: 여러 채널에서 트럼프 관련 발언/뉴스를 수집하고 구조화된 데이터로 변환

**주요 책임**:
- 다양한 채널 모니터링 및 데이터 수집
- Raw 데이터를 구조화된 형태로 변환
- 메타데이터 추출 (발언 시간, 채널, 원문 링크 등)
- 트럼프 발언인지 검증
- 실시간/준실시간 수집 스케줄링
- **이미 수집한 데이터 추적 및 스킵** (중복 수집 방지)
- **원본 데이터 저장** (재분석 및 감사 목적)

**필요한 컴포넌트**:
- **Channel Collectors** (채널별 수집기)
  - Truth Social Collector: Truth Social 게시물 수집 + 데이터 추출
  - News Collector: 주요 뉴스 사이트에서 본문 수집 및 추출 (약 10개 채널)
  - Press Release Collector: 공식 발표문 수집
- **Scheduler**: 각 채널별 수집 주기 관리
- **State Manager**: 각 채널별 마지막 수집 지점 추적 및 관리
- **Content Validator**: 트럼프 발언이 맞는지 검증 (이름, 계정 확인 등)
- **Raw Data Store**: 원본 데이터 저장

**예상 데이터량**: 약 120개/일 (트럼프 발언 10개 × 채널 12개)

---

### 2. 분석 레이어 (Analysis Layer)
**역할**: 수집된 원본 데이터를 LLM으로 가공 및 분석

**주요 책임**:
- 긴 텍스트를 임베딩 모델의 토큰 제한 이내로 요약 (영어, 중복 제거용)
- 3줄 요약 생성
- 관련 산업 식별 (예: 반도체, 자동차, 철강, 에너지 등)
- **분석 데이터 저장** (중복 제거 및 피드 생성에 활용)

**필요한 컴포넌트**:
- **LLM Service**: 한 번의 호출로 모든 분석 수행
- **Analysis Store**: 분석 결과 저장

---

### 3. 중복 제거 레이어 (Deduplication Layer)
**역할**: 임베딩 기반 의미 유사도로 중복 필터링

**주요 책임**:
- 2번 레이어의 짧은 요약을 임베딩 벡터로 변환
- **최근 24-48시간 내 저장된 임베딩 데이터와 비교**
- 코사인 유사도로 중복 감지 (임계값: 0.85 이상)
- **중복 발견 시**: 먼저 처리된 데이터를 유지, 나중 데이터는 중복 이력으로 저장 후 처리 중단
- **중복이 아닐 시**: 다음 레이어로 전달 및 임베딩 데이터 저장

**필요한 컴포넌트**:
- **Embedding Generator**: 임베딩 모델을 사용한 벡터 생성
- **Similarity Matcher**: 코사인 유사도 계산 (1 대 N 비교)
- **Vector Store**: 임베딩 데이터 저장 및 검색
  - 옵션 1: Vector DB (Pinecone, Weaviate, ChromaDB)
  - 옵션 2: Redis + 인메모리 검색
  - 옵션 3: PostgreSQL + pgvector
- **Duplicate History Store**: 중복 이력 저장 (추적 및 분석용)
- **Time-window Manager**: 오래된 임베딩 데이터 자동 삭제 (24-48시간 윈도우)

---

### 4. 피드 생성 레이어 (Feed Generation Layer)
**역할**: 최종 사용자에게 제공될 피드 아이템 생성 및 저장

**주요 책임**:
- 2번 레이어의 분석 결과와 이에 매칭되는 원본 데이터 정보를 피드 형식으로 변환
- **피드 데이터 저장** (API에서 조회할 수 있도록)

**필요한 컴포넌트**:
- **Feed Builder**: 피드 아이템 생성 (요약, 관련 산업, 원문 링크 등 포함)
- **Formatter**: 일관된 피드 형식 생성
- **Feed Store**: 생성된 피드 저장

**특징**: 2번 레이어에서 이미 모든 분석이 완료되어 단순 변환만 수행

---

### 5. API 레이어 (API Layer)
**역할**: 프론트엔드에 피드 데이터 제공

**주요 책임**:
- 피드 데이터 조회 인터페이스 제공
- 시간순 정렬 (최신순)
- 실시간 새 피드 전달
- 필터링/검색 기능 (산업별, 날짜별 등)
- 페이지네이션
- **저장된 피드 데이터 조회**

**필요한 컴포넌트**:
- **Request Handler**: 클라이언트 요청 처리
- **Real-time Notifier**: 새 피드 발생 시 실시간 알림
- **Query Processor**: 검색/필터 처리
- **Data Fetcher**: 저장된 피드 조회

---

## 전체 데이터 흐름

```
[다양한 채널 - Truth Social, News, Press Release]
    ↓
[1. 데이터 수집]
   - 채널별 Collector가 수집 + 구조화
   - 마지막 수집 지점 이후의 새 데이터만 수집
   - 원본 데이터 저장 → Raw Data Store
   - 수집: 약 120개/일
    ↓
[2. 분석]
   - LLM 호출 1회로 모든 분석 수행
     • 짧은 요약 (중복 제거용)
     • 3줄 요약
     • 관련 산업 식별
   - 분석 결과 저장 → Analysis Store
    ↓
[3. 중복 제거]
   - 짧은 요약 → 임베딩 벡터 생성
   - Vector Store 조회 (최근 24-48시간)
   - 코사인 유사도 비교 (1:N)
   - 중복이면 → Duplicate History Store + 처리 중단
   - 통과하면 → Vector Store 저장 + 다음 레이어 전달
    ↓
[4. 피드 생성]
   - 분석 결과를 피드 형식으로 변환
   - 피드 저장 → Feed Store
    ↓
[5. API] → [프론트엔드]
   - 저장된 피드 조회 및 시간순 정렬
   - 실시간 새 피드 알림
```

---

## 레이어 간 통신 방식

### 비동기 메시지 기반 처리

각 레이어는 **메시지 큐**를 통해 비동기적으로 통신합니다. 이를 통해 각 레이어가 독립적으로 동작하며, 확장성과 장애 격리가 가능합니다.

### 메시지 페이로드 원칙

각 레이어는 다음 레이어가 **추가 DB 조회 없이** 바로 처리할 수 있도록 필요한 모든 데이터를 메시지에 포함합니다.

### 처리 흐름

```
[1. 데이터 수집]
   ↓ (원본 데이터 저장)
   ↓ (메시지 발행: ID + raw data payload)
   
[메시지 큐]
   ↓
   
[2. 분석] ← 메시지 구독
   ↓ (LLM 분석 수행)
   ↓ (분석 결과 저장)
   ↓ (메시지 발행: ID + analysis payload)
   
[메시지 큐]
   ↓
   
[3. 중복 제거] ← 메시지 구독
   ↓ (임베딩 생성 및 유사도 비교)
   ↓ (중복이 아니면 메시지 발행: ID + analysis payload)
   ↓ (중복이면 이력 저장 후 중단)
   
[메시지 큐]
   ↓
   
[4. 피드 생성] ← 메시지 구독
   ↓ (피드 생성 및 저장)
   ↓ (메시지 발행: feed ID)
   
[메시지 큐]
   ↓
   
[5. API] ← 메시지 구독
   ↓ (실시간 알림 전송)
```

### 장점

- **독립성**: 각 레이어가 독립적으로 배포 및 확장 가능
- **확장성**: 처리량이 많은 레이어만 인스턴스 추가 가능
- **복원력**: 메시지가 큐에 보존되어 실패 시 재처리 가능
- **병렬 처리**: 데이터 수집이 분석 완료를 기다릴 필요 없음

---

## 저장소 구조

각 레이어는 독립적인 저장소를 사용하여 데이터를 관리합니다.

| 레이어 | 저장소 | 저장 데이터 | 용도 |
|--------|--------|-----------|------|
| **1. 데이터 수집** | Raw Data Store | 원본 데이터 (내용, 메타데이터) | 재분석, 감사 |
| **2. 분석** | Analysis Store | 요약, 산업 | 중복 제거, 피드 생성 |
| **3. 중복 제거** | Vector Store | 임베딩 데이터 (24-48시간) | 유사도 비교 |
| **3. 중복 제거** | Duplicate History Store | 중복 이력 | 추적, 분석 |
| **4. 피드 생성** | Feed Store | 최종 피드 데이터 | API 조회 |

---

## 주요 고려사항

### 성능 요구사항
- **실시간성**: 발언 발생 후 몇 분 내 피드 생성 목표
- **처리량**: 동시에 여러 채널 모니터링 가능
- **확장성**: 채널 추가 시 쉽게 확장 가능한 구조

### 데이터 품질
- **정확성**: 오역이나 잘못된 해석 최소화
- **신뢰성**: 검증된 채널만 활용
- **완전성**: 다중 채널 모니터링을 통한 중요 발언 누락 방지
- **중복 제거 정확도**: 임베딩 기반 의미 유사도로 향상

### 운영 요구사항
- **모니터링**: 각 레이어별 상태 추적
- **에러 핸들링**: 특정 채널 장애 시에도 서비스 지속
- **로깅**: 문제 발생 시 추적 가능한 로그
- **데이터 관리**: 각 레이어에서 필요한 데이터 직접 저장 및 조회

### 비용 효율성
- **LLM 비용**: 한 번의 호출로 모든 분석 완료
- **예상 비용**: 예상 일일 수집량 기준 합리적 수준
- **중복 제거**: 불필요한 처리 최소화

---

## 설계 변경 이유

### 1. 레이어 순서 변경 (수집 → 분석 → 중복 제거)
**문제**: 긴 텍스트(5,000+ 토큰)를 임베딩 모델(512 토큰 제한)로 직접 처리 시 앞부분만 반영되어 핵심 내용 누락 가능

**해결**: LLM으로 먼저 요약하여 전체 내용을 압축한 후 임베딩 생성

### 2. 분석 레이어에서 모든 분석 수행
**효율**: 한 번의 LLM 호출로 요약, 관련 산업 분석을 모두 수행하여 비용 절감

### 3. 임베딩 기반 중복 제거
**정확도**: 임베딩 유사도로 의미론적 중복 감지

### 4. 먼저 처리된 순서 우선
**단순성**: 신뢰도 평가 없이 먼저 들어온 데이터를 원본으로 유지

### 5. Vector Store 도입
**확장성**: 최근 24-48시간 임베딩 데이터를 저장하여 효율적인 1:N 유사도 비교

---

## 다음 단계
1. 각 레이어별 구체적인 구현 방법 결정
2. 기술 스택 선정 (LLM 모델, 임베딩 모델, Vector DB 등)
3. 데이터 채널 구체화 (뉴스 채널 선정)
4. 임베딩 모델 및 유사도 임계값 실험