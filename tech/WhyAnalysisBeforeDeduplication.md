# 왜 분석이 중복 제거보다 먼저인가?

## 문서 개요

이 문서는 트럼프 스캔 시스템에서 "분석 레이어"를 "중복 제거 레이어"보다 먼저 배치한 이유를 설명합니다.

---

## 결정 내용

**채택한 순서:**
```
수집 → 분석 → 중복 제거 → 피드 생성
```

**기각한 순서:**
```
수집 → 중복 제거 → 분석 → 피드 생성
```

---

## 문제 정의

중복 제거는 임베딩 벡터 비교를 통해 수행됩니다. 이때 **무엇을 임베딩할 것인가?**가 핵심 질문입니다:

- **Option A**: 원본 텍스트 (Raw Data)를 직접 임베딩
- **Option B**: LLM이 생성한 요약 (Semantic Summary)을 임베딩

---

## 고려한 옵션

### Option A: 수집 → 중복 제거 → 분석

**흐름:**
```
1. 원본 텍스트 수집
2. 원본 텍스트를 임베딩
3. 임베딩 벡터로 중복 검사
4. 고유한 데이터만 LLM 분석
```

**장점:**
- LLM 비용 절감 (중복 데이터는 분석하지 않음)
- 더 빠른 처리 시간
- 직관적인 구조 (먼저 필터링, 나중에 분석)

**단점:**
- 긴 텍스트 처리의 기술적 한계
- 노이즈가 많은 원본 텍스트로 인한 정확도 저하
- 구현 복잡도 증가

---

### Option B: 수집 → 분석 → 중복 제거 (채택)

**흐름:**
```
1. 원본 텍스트 수집
2. 모든 데이터를 LLM으로 분석 (요약 생성)
3. 요약을 임베딩
4. 임베딩 벡터로 중복 검사
```

**장점:**
- 짧고 정제된 텍스트로 정확한 중복 제거
- 모든 임베딩 모델과 호환
- 구조가 단순하고 구현이 빠름
- 표준화된 형식으로 일관된 비교

**단점:**
- 중복 데이터도 LLM 분석 수행 (비용 발생)
- 전체 처리 시간 증가

---

## 선택 근거

### 1. 기술적 제약: 텍스트 길이 문제

**데이터 소스별 특성:**

| 소스 | 평균 길이 | 특징 |
|------|----------|------|
| Truth Social | 500자 | 짧은 발언 |
| Twitter | 280자 | 짧은 발언 |
| 뉴스 기사 | 3000-5000자 | 긴 텍스트 |

**임베딩 모델의 토큰 제한:**

| 모델 유형 | 토큰 제한 | 대략 글자수 |
|----------|----------|------------|
| 오픈소스 (multilingual-e5-small) | 512 tokens | ~1000자 |
| 상용 (OpenAI embedding) | 8191 tokens | ~16000자 |

**문제:**
- 뉴스 기사(3000-5000자)는 오픈소스 임베딩 모델의 제한(~1000자)을 초과
- 텍스트를 잘라서 임베딩하면 핵심 내용(인용 부분)을 놓칠 수 있음
- 텍스트를 여러 조각으로 나누면(청킹) 계산량이 급증하고 구현이 복잡해짐

**해결:**
- LLM이 생성한 요약은 항상 짧음 (100-200 단어)
- 모든 임베딩 모델로 처리 가능
- 추가 처리 불필요

---

### 2. 정확도: 노이즈 제거

**시나리오 예시:**

```
Truth Social 원본 (50자):
"China must stop unfair trade practices"

CNN 기사 원본 (5000자):
"[2000자: 배경 - 지난 3년간 무역전쟁 역사]
트럼프 대통령은 'China must stop unfair trade practices'라고 발언했다.
[3000자: 전문가 분석, 시장 반응, 향후 전망]"
```

**원본 텍스트 임베딩 시:**
- 전체 텍스트의 90%는 배경 설명과 분석 (노이즈)
- 10%만 실제 발언 내용 (시그널)
- 두 텍스트의 유사도가 실제보다 낮게 계산됨
- 중복 제거 실패 → 같은 발언이 여러 피드로 생성

**Semantic Summary 임베딩 시:**
```
Truth Social 요약:
"Trump criticizes China trade practices"

CNN 기사 요약:
"Trump criticizes China trade practices and announces tariffs"

유사도: 높음 → 중복으로 정확히 감지
```

---

### 3. 표준화: 다양한 형식의 통일

**다양한 소스의 같은 내용:**

```
Truth Social:
"China bad, tariffs good! 25%!"

CNN:
"트럼프 대통령은 오늘 중국의 불공정 무역관행을 비판하며 25% 관세를 발표했습니다."

BBC:
"President Trump has announced a 25% tariff on Chinese goods, citing unfair trade practices."
```

**원본 임베딩 시:**
- 세 텍스트가 매우 다름 (언어, 길이, 스타일)
- 유사도 낮음 → 중복 감지 실패

**Semantic Summary 임베딩 시:**
```
모두 다음과 유사하게 요약됨:
"Trump announces 25% tariffs on Chinese goods due to unfair trade practices"

유사도: 높음 → 정확한 중복 감지
```

---

### 4. MVP 전략: 빠른 검증 우선

**현재 단계의 목표:**
- 시스템 전체 구조 검증
- 실제 데이터로 중복률 측정
- 사용자 피드백 수집

**단순한 구조의 이점:**
- 빠른 구현과 배포
- 문제 발생 시 디버깅 용이
- 실제 운영 데이터 확보 후 최적화 가능

---

## 트레이드오프

| 측면 | 현재 설계 (분석 먼저) | 대안 (중복제거 먼저) |
|------|---------------------|-------------------|
| 중복 제거 정확도 | ✅ 높음 | ⚠️ 낮음 (긴 텍스트/노이즈) |
| LLM 비용 | ❌ 높음 (중복도 분석) | ✅ 낮음 |
| 구현 복잡도 | ✅ 단순 | ❌ 복잡 (청킹, 다중 임베딩) |
| 전체 처리 속도 | ⚠️ 느림 | ✅ 빠름 |
| 임베딩 모델 선택 | ✅ 제약 없음 | ⚠️ 제한적 (긴 텍스트 지원 필요) |
| 디버깅 난이도 | ✅ 쉬움 | ❌ 어려움 |

---

## 비용 추정

**가정:**
- 일일 수집: 120개
- 중복률: 50% (추정)
- LLM 비용: 건당 $0.01 (Gemini 2.0 Flash 기준)

**현재 설계의 비용:**
```
일일 분석 횟수: 120개 (모두 분석)
불필요한 분석: 60개 (중복이지만 분석됨)
일일 낭비: 60 × $0.01 = $0.60
월간 낭비: $0.60 × 30 = $18
```

**대안 설계의 비용:**
```
일일 분석 횟수: 60개 (중복 제거 후)
불필요한 분석: 0개
월간 절감: $18
```

**판단:**
- MVP 단계에서 월 $18의 추가 비용은 수용 가능
- 정확도와 단순성이 더 중요

---

## 재검토 조건

다음 조건 중 하나라도 만족하면 레이어 순서를 재검토합니다:

### 조건 1: 높은 중복률과 비용

```
IF 실측 중복률 > 70% AND 월간 LLM 비용 > $100
THEN 2단계 중복 제거 방식 검토
```

**2단계 중복 제거:**
```
1차: 원본 텍스트 간단 체크
   - 텍스트 해시 비교
   - 또는 첫 500자만 임베딩
   - 완전 중복/매우 유사한 것만 필터링

2차: Semantic Summary 정밀 체크
   - 1차를 통과한 데이터만 분석
   - 요약 생성 후 임베딩
   - 의미적 중복까지 필터링
```

### 조건 2: 기술 환경 변화

```
IF OpenAI 임베딩 사용 결정
THEN 원본 전체 임베딩 가능 (8K tokens 지원)
   → 레이어 순서 변경 재검토
```

### 조건 3: 데이터 특성 변화

```
IF 수집 데이터의 90% 이상이 짧은 텍스트 (1000자 이하)
THEN 원본 임베딩으로도 충분
   → 레이어 순서 변경 고려
```

---

## 향후 최적화 옵션

### Option 1: 2단계 중복 제거

위에서 설명한 1차(간단) + 2차(정밀) 방식

**장점:** 비용 절감
**단점:** 구현 복잡도 증가

---

### Option 2: 채널별 차별화

```
공식 채널 (Truth Social, 백악관):
→ 바로 분석 (원본이 짧고 중요도 높음)

뉴스 매체:
→ 원본으로 1차 필터링
→ 통과한 것만 분석
```

**장점:** 중요한 채널 우선 처리, 비용 최적화
**단점:** 구현 및 관리 복잡도 증가

---

### Option 3: 상용 임베딩 사용

OpenAI embedding 사용 시:
- 긴 텍스트도 전체 임베딩 가능 (8K tokens)
- 원본 텍스트로도 정확한 중복 제거
- 비용: $0.00002/1K tokens (매우 저렴)

**검토:** LLM 비용과 임베딩 비용 비교 후 결정

---

## 결론

현재 "분석 → 중복 제거" 순서는:

**✅ 강점:**
- 정확한 중복 제거 (짧고 정제된 텍스트 사용)
- 단순한 구조 (빠른 구현과 디버깅)
- 모든 임베딩 모델과 호환
- MVP에 적합한 접근

**⚠️ 약점:**
- LLM 비용 발생 (중복도 분석)
- 전체 처리 시간 증가

**전략:**
1. MVP는 현재 설계로 시작
2. 실제 운영 데이터 수집 (중복률, 비용, 처리 시간)
3. 데이터 기반으로 최적화 여부 결정

정확도와 단순성을 우선시하되, 확장 가능한 구조를 유지합니다.