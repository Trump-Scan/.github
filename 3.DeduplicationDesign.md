# 중복 제거 레이어 설계

## 문서 개요

본 문서는 트럼프 스캔 서비스의 데이터 중복 제거 레이어 설계를 다룹니다. 구현 세부사항보다는 전체적인 구조와 개념, 그리고 고려해야 할 사항들을 중심으로 기술합니다.

---

## 1. 레이어 개요

### 1.1 목적

여러 채널에서 수집된 데이터 중 유사한 내용을 식별하여 중복을 제거하고, 고유한 발언만 다음 레이어로 전달합니다.

### 1.2 핵심 책임

- 유사 내용 감지 (같은 발언의 다른 표현)
- 최근 데이터와의 비교 (시간 윈도우 내)
- 중복 발견 시 먼저 도착한 것 유지 (순차 처리)
- 중복된 항목 즉시 필터링 (빠른 처리)
- 다음 레이어(분석)로 검증된 데이터만 전달

### 1.3 왜 중복 제거가 중요한가?

**현실적인 시나리오**:
- 트럼프가 Truth Social에 발언 게시
- 뉴스 매체들이 해당 발언을 인용하여 기사 작성
- 결과: 하나의 발언이 여러 채널에서 수집됨

**중복 제거 없이 발생하는 문제**:
- 동일한 발언에 대해 여러 번 분석 수행 (비용 낭비)
- 피드에 같은 내용이 반복 노출 (사용자 경험 저하)
- 불필요한 알림 발생
- 시스템 리소스 낭비

### 1.4 요구사항

**기능 요구사항**:
- 유사도 기반 감지 (텍스트 유사도)
- 시간 윈도우 내 데이터만 비교 (예: 최근 24시간)
- 순차 처리 (먼저 도착한 것 유지)
- 처리 지연 최소화

**비기능 요구사항**:
- **속도**: 중복 체크는 2-3초 이내
- **정확성**: False Positive(잘못된 중복 판정) 최소화
- **확장성**: 데이터 증가에 대응 가능
- **신뢰성**: 중복 제거 실패 시에도 데이터는 통과

---

## 2. 아키텍처 구조

### 2.1 전체 구조

```
   [Data Collection Layer]
            │
            ↓
      [Message Queue] ← 레이어 간 통신
            │
            ↓
┌──────────────────────────────────────────────────────────────┐
│                  Deduplication Layer                         │
├──────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  Message Consumer                                      │  │
│  │  - 메시지 수신 및 파싱                                │  │
│  └────────┬───────────────────────────────────────────────┘  │
│           │                                                   │
│           │ (데이터 ID)                                      │
│           ↓                                                   │
│  ┌────────────────────┐                                      │
│  │   Data Query       │ ← DB에서 원본 데이터 조회           │
│  └────────┬───────────┘                                      │
│           │                                                   │
│           │ (원본 데이터)                                    │
│           ↓                                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  Similarity Detector                                   │  │
│  │  - 최근 데이터와 유사도 계산                          │  │
│  └────────┬───────────────────────────────────────────────┘  │
│           │                        ↕                          │
│           │                  [Data Query]                     │
│           │              (최근 N시간 데이터 조회)            │
│           │                                                   │
│           ↓ (판정 결과)                                      │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  Decision Handler                                      │  │
│  │  - 중복이면 → Dedup History 기록, 처리 중단          │  │
│  │  - 고유하면 → 메시지 발행 (분석 레이어로)            │  │
│  └────────┬───────────────────────────────────────────────┘  │
│           │                        ↓                          │
│           │                  ┌─────────────┐                 │
│           │                  │Dedup History│                 │
│           │                  └─────────────┘                 │
│           │                                                   │
└───────────┼───────────────────────────────────────────────────┘
            │
            ↓ (고유 데이터만)
      [Message Queue] ← 레이어 간 통신
            │
            ↓
      [Analysis Layer]
```

**컴포넌트 역할:**
- **Message Consumer**: 메시지 수신 및 조율
- **Data Query**: DB 조회 (원본 데이터, 최근 데이터)
- **Similarity Detector**: 텍스트 유사도 계산
- **Decision Handler**: 중복 판정 결과 처리
- **Dedup History**: 중복 이력 저장

### 2.2 처리 흐름

```
1. 메시지 수신
   - 데이터 수집 레이어로부터 "새 데이터 ID=123" 메시지 받음
   
2. 원본 데이터 조회
   - Raw Data Store에서 ID=123 데이터 조회
   - 내용, 채널, 발언 시간 등 확인
   
3. 유사도 검사 (Similarity Check)
   - 최근 N시간 내 데이터와 텍스트 유사도 계산
   - 임계값 이상이면 → 중복 후보로 식별
   
4. 중복 해결 (Duplicate Resolution)
   - 중복 후보 발견 시 → 중복 판정
   - 현재 데이터 처리 중단
   - (먼저 처리된 것이 이미 존재하므로)
   
5. 결과 처리
   - 고유 데이터: 다음 레이어로 메시지 발행
   - 중복 데이터: 처리 중단, 이력 기록
```

### 2.3 주요 개념

**유사 중복 (Near Duplicate)**
- 내용은 같지만 표현이 다른 경우
- 텍스트 유사도 기반 검사
- 예: 뉴스 기사가 발언을 인용하되 약간 수정

**시간 윈도우 (Time Window)**
- 중복 체크를 수행할 시간 범위
- 예: 최근 24시간 내 데이터만 비교
- 오래된 데이터는 중복 체크 제외

---

## 3. 핵심 컴포넌트

### 3.1 Message Consumer (메시지 소비자)

**역할**

데이터 수집 레이어로부터 메시지를 받아 처리를 시작합니다.

**처리 흐름**
```
1. 메시지 큐에서 메시지 수신
2. 메시지 파싱 (데이터 ID 추출)
3. 원본 데이터 조회
4. Deduplication Engine으로 전달
5. 처리 결과에 따라 다음 행동 결정
```

**에러 처리**
- 원본 데이터 조회 실패: 재시도 (최대 3회)
- 메시지 파싱 실패: Dead Letter Queue로 이동
- 시스템 에러: 메시지를 큐에 반환하여 나중에 재처리

### 3.2 Similarity Detector (유사도 감지기)

**역할**

내용은 같지만 표현이 다른 유사 중복을 감지합니다.

**동작 방식**

1. **후보 데이터 조회**
    - 최근 N시간(예: 24시간) 내 데이터 조회
    - 같은 채널은 제외 (다른 채널 간 비교만)

2. **유사도 계산**
    - 각 후보와 현재 데이터의 유사도 계산
    - 여러 알고리즘 활용 가능

3. **임계값 비교**
    - 유사도가 임계값(예: 0.85) 이상이면 중복 후보
    - 여러 후보 발견 시 가장 유사도 높은 것 선택

**유사도 측정 알고리즘**

다양한 방법을 단계적으로 적용할 수 있습니다:

*1단계: 토큰 기반 유사도 (빠름)*
- Jaccard Similarity
- Cosine Similarity
- Token Overlap Ratio

*2단계: 편집 거리 기반 (중간)*
- Levenshtein Distance
- Damerau-Levenshtein Distance

*3단계: 의미 기반 (느림, 정확)*
- 임베딩 벡터 비교 (Sentence Transformers)
- BERT 기반 유사도

**실용적 접근 방식**

초기에는 간단한 방법으로 시작하고 점진적으로 개선:
1. Phase 1: Token Overlap (빠르고 간단)
2. Phase 2: Cosine Similarity 추가
3. Phase 3: 필요시 임베딩 기반 고도화

**예시**
```
원문 1 (Truth Social): 
"China must stop unfair trade practices immediately!"

원문 2 (뉴스 기사): 
"President Trump stated that China should halt its unfair trade practices right away."

→ 의미는 같지만 표현이 다름
→ 토큰 유사도: 0.4 (낮음)
→ 의미 기반 유사도: 0.9 (높음)
→ 중복으로 판정 가능
```

**임계값 설정**

유사도 임계값은 중요한 파라미터입니다:
- 너무 낮으면: 다른 내용도 중복으로 판정 (False Positive)
- 너무 높으면: 실제 중복을 놓침 (False Negative)

권장 초기값: 0.85 (이후 실제 데이터로 조정)

**임계값에 따른 처리**

```
유사도 >= 0.85:
  → 중복으로 판정
  → 나중 데이터 중단

유사도 < 0.85:
  → 중복 아님
  → 별도 피드로 처리
```

**예시: 유사도 낮은 경우 (별도 피드)**
```
1. Twitter 발언 (10:00)
   "중국 관세!"
   → 통과 → "트럼프 발언" 피드 생성
   
2. 백악관 공식 발표 (14:00)
   "중국산 제품에 대한 관세 정책 상세 발표문..."
   → 유사도 체크: 0.7 (< 0.85)
   → 중복 아님 → 통과 → "관세 정책 발표" 별도 피드 생성
   
결과: 
- 빠른 발언으로 먼저 알림
- 상세한 발표도 별도 제공
- 둘 다 가치 있음
```

**성능 최적화**

유사도 계산은 비용이 높으므로:
- **후보 개수 제한** (예: 최근 100개만 비교)
- **조기 종료** (임계값 이상 발견 시 즉시 중단)
- **임베딩 캐싱** (선택적):
  ```
  텍스트 → 벡터 변환 결과를 캐싱
  - 같은 텍스트를 여러 번 임베딩하지 않음
  - 유사도 계산 자체는 캐싱 불가 (조합 폭발)
  ```
- **병렬 처리** (여러 후보를 동시에 비교)

### 3.3 Decision Handler (결정 처리기)

**역할**

중복 체크 결과를 바탕으로 최종 행동을 결정하고 실행합니다.

**핵심 원칙: 완전한 순차 처리**

먼저 처리된 것이 항상 우선:
```
규칙: 먼저 도착한 메시지가 통과
   → 나중에 같은 내용 발견 시 무조건 중복 처리
   → 채널은 중요하지 않음 (모두 검증된 채널)
   → 교체 로직 없음 (단순함)
```

**처리 분기**

```
IF 중복 아님:
    1. 메시지 발행 (분석 레이어로)
    2. 메트릭 기록 (고유 데이터)
    
ELSE:
    # 중복 = 이미 처리된 데이터가 존재
    1. 처리 중단
    2. 중복 이력 기록
       - 현재 데이터 ID
       - 원본 데이터 ID (먼저 도착한 것) ⭐
       - 유사도, 채널 등
    3. 메트릭 기록 (중복 필터됨)
```

**중복 추적의 가치**:
- 많은 중복을 가진 발언 = 여러 채널에서 보도됨 = 중요도 높음
- 논문의 인용 지수처럼 활용 가능

**처리 시나리오**

*시나리오 1: 일반적인 경우*
```
1. Truth Social 발언 도착 (10:00)
   → 중복 없음 → 통과 → 분석 레이어로
   
2. 뉴스 기사 도착 (10:15)
   → 중복 감지 → 중단
   → 이력 기록: original_id = Truth Social 데이터
```

*시나리오 2: 뉴스가 먼저*
```
1. Reuters 속보 도착 (09:55)
   → 중복 없음 → 통과 → 분석 레이어로
   
2. Truth Social 원본 도착 (10:00)
   → 중복 감지 → 중단
   → 이력 기록: original_id = Reuters 데이터
   
결과: 뉴스가 먼저 피드에 노출 (속도 우선)
```

*시나리오 3: 거의 동시*
```
1. Truth Social 도착 (10:00:00)
   → 통과
   
2. 뉴스 도착 (10:00:30)
   → 중복 감지 → 중단
   
결과: 30초 빠른 Truth Social 사용 (채널 무관)
```

**Edge Case**

*완전히 동시 도착*
```
메시지 큐의 순서가 결정
→ 먼저 처리된 것이 통과
→ 예측 불가능하지만 문제없음
   (둘 다 검증된 소스)
```

### 3.4 Dedup History (중복 이력 저장소)

**역할**

중복으로 판정된 데이터의 이력을 기록합니다.

**저장 정보**
- 중복 데이터 ID (필터링된 것)
- 원본 데이터 ID (먼저 통과한 것) ⭐
- 유사도 점수
- 채널 정보
- 감지 시각

**활용 목적**
- 추적 및 분석
- 인용 지수 계산 (향후)
- 중복 패턴 파악
- 디버깅

**쿼리 예시**
```sql
-- 특정 발언의 중복 횟수 확인
SELECT COUNT(*) as duplicate_count
FROM dedup_history
WHERE original_id = 'data_123'

-- 가장 많이 중복된 발언 TOP 10
SELECT original_id, COUNT(*) as citation_count
FROM dedup_history
GROUP BY original_id
ORDER BY citation_count DESC
LIMIT 10
```

---

## 4. 중복 감지 알고리즘 상세

### 4.1 단계별 알고리즘

**Level 1: 토큰 기반 유사도 (Token-based Similarity)**

간단하면서도 효과적인 방법입니다.

```
알고리즘: Jaccard Similarity

1. 토큰화
   tokens1 = tokenize(text1)  # {"china", "trade", "tariff", ...}
   tokens2 = tokenize(text2)

2. Jaccard 계산
   intersection = tokens1 ∩ tokens2
   union = tokens1 ∪ tokens2
   similarity = |intersection| / |union|

3. 판정
   IF similarity >= threshold (0.85):
       RETURN Similar
   ELSE:
       RETURN Different
```

**예시**:
```
Text 1: "China must stop unfair trade"
Text 2: "China should halt unfair trade"

Tokens 1: {china, must, stop, unfair, trade}
Tokens 2: {china, should, halt, unfair, trade}

Intersection: {china, unfair, trade} (3개)
Union: {china, must, stop, should, halt, unfair, trade} (7개)

Jaccard = 3/7 ≈ 0.43 → 유사하지 않음
```

**시간 복잡도**: O(M * K) - M은 후보 개수, K는 평균 토큰 수  
**공간 복잡도**: O(K)

**Level 2: 의미 기반 유사도 (Semantic Similarity)**

높은 정확도가 필요할 때 사용합니다.

```
알고리즘: Sentence Embedding + Cosine Similarity

1. 임베딩 벡터 계산
   vec1 = sentence_transformer.encode(text1)  # 384차원 벡터
   vec2 = sentence_transformer.encode(text2)

2. Cosine Similarity 계산
   similarity = cos_similarity(vec1, vec2)
   
3. 판정
   IF similarity >= threshold (0.85):
       RETURN Similar
   ELSE:
       RETURN Different
```

**예시**:
```
Text 1: "China must stop unfair trade"
Text 2: "China should halt unfair trade"

Embedding Vector 1: [0.23, -0.45, 0.12, ..., 0.89]  # 384차원
Embedding Vector 2: [0.21, -0.43, 0.15, ..., 0.87]

Cosine Similarity: 0.92 → 매우 유사
```

**시간 복잡도**: O(M * E) - M은 후보 개수, E는 임베딩 시간  
**공간 복잡도**: O(D) - D는 임베딩 벡터 차원

### 4.2 하이브리드 접근

실용적으로는 여러 방법을 조합합니다:

```
Pipeline:
1. Quick Filter (토큰 길이, 날짜 등)
   IF clearly different → PASS
   
2. Token-based Similarity (빠름)
   IF similarity < 0.5 → PASS
   IF similarity >= 0.85 → DUPLICATE
   
3. Semantic Similarity (느림, 경계선만)
   IF 0.5 <= similarity < 0.85:
       semantic_sim = compute_semantic_similarity()
       IF semantic_sim >= 0.85 → DUPLICATE
```

이 접근법의 장점:
- 대부분의 케이스는 빠른 방법으로 처리
- 어려운 경우만 정교한 방법 사용
- 평균 처리 시간 최소화

### 4.3 임계값 튜닝

임계값은 실제 데이터로 조정해야 합니다:

**초기 권장값**:
- Token-based: 0.80
- Semantic: 0.85

**조정 방법**:
1. 샘플 데이터로 테스트
2. False Positive / False Negative 비율 확인
3. 비즈니스 요구사항에 맞게 조정
    - False Positive 줄이려면: 임계값 ↑
    - False Negative 줄이려면: 임계값 ↓

---

## 5. 에러 처리

### 5.1 에러 유형과 대응

**데이터 조회 실패**
- 증상: DB 연결 끊김, 타임아웃
- 대응: 재시도 (최대 3회), 실패 시 메시지를 큐에 반환

**유사도 계산 실패**
- 증상: 모델 로딩 실패, 메모리 부족
- 대응: 토큰 기반으로 fallback
- 로그 기록 및 알림

**메시지 발행 실패**
- 증상: 메시지 큐 다운
- 대응: 재시도 (exponential backoff)
- Dead Letter Queue로 이동

### 5.2 Fallback 전략

시스템 장애 시에도 서비스는 계속되어야 합니다:

```
Primary: 
  토큰 기반 + 의미 기반 유사도 검사

Fallback Level 1 (의미 기반 모델 장애):
  토큰 기반만 수행

Fallback Level 2 (전체 장애):
  중복 체크 없이 모두 통과
  (다운스트림에서 처리)
```

### 5.3 데이터 일관성

**원칙**: 데이터 손실보다 중복 허용이 나음

- 확실하지 않으면 통과시킴
- 중복 제거 실패는 치명적이지 않음
- 다만 메트릭으로 추적하여 모니터링

---

## 6. 모니터링

### 6.1 핵심 메트릭

**처리 메트릭**
- 시간당 처리된 메시지 수
- 중복으로 필터링된 비율
- 평균 처리 시간
- 처리 대기 큐 길이

**정확도 메트릭**
- False Positive 추정치
- False Negative 추정치
- 유사도 분포 (히스토그램)

**성능 메트릭**
- 유사도 계산 시간
- DB 조회 시간
- 임베딩 캐시 히트율 (의미 기반 유사도 사용 시)

**에러 메트릭**
- 에러 발생 횟수 (유형별)
- 재시도 횟수
- Fallback 활성화 횟수

### 6.2 알림 조건

**즉시 알림**
- 처리 대기 큐가 1000개 초과
- 에러율이 5% 초과
- 평균 처리 시간이 5초 초과
- 유사도 모델 장애 발생

**경고 알림**
- 중복 필터링 비율 급증 (평소의 2배)
- 유사도 계산 실패 증가

### 6.3 대시보드

**실시간 모니터링**
- 처리량 그래프 (분당)
- 중복 필터링 비율
- 평균 처리 시간 추이
- 현재 에러 상태

**통계 및 분석**
- 시간대별 중복 패턴
- 채널별 중복 비율
- 유사도 분포
- 채널별 통과율 (어떤 채널이 자주 먼저 도착하는가)
- **인용 지수 기반 중요도**:
  ```sql
  -- 가장 많이 중복된 발언 TOP 10
  SELECT original_id, COUNT(*) as citation_count
  FROM dedup_history
  GROUP BY original_id
  ORDER BY citation_count DESC
  LIMIT 10
  ```

---

## 7. 확장성 고려사항

### 7.1 수평 확장 (Scale Out)

**여러 인스턴스 실행**

중복 제거 레이어는 stateless하게 설계하여 쉽게 확장 가능합니다:

```
[Message Queue]
    ↓
[Instance 1] [Instance 2] [Instance 3]
    ↓           ↓           ↓
  처리        처리        처리
```

**주의사항**:
- 메시지는 큐에서 하나의 인스턴스로만 전달
- DB 연결 풀 관리

### 7.2 데이터 증가 대응

**시간 윈도우 최적화**

데이터가 많아지면 비교 대상이 증가합니다:
- 초기: 24시간 윈도우
- 데이터 증가 시: 6시간으로 축소
- 또는 최대 N개로 제한

**샤딩 고려**

채널별로 독립적으로 처리:
```
[Truth Social 메시지] → [Dedup Instance 1]
[News 메시지]         → [Dedup Instance 2]
```

단, 채널 간 중복 체크는 어려워짐

### 7.3 성능 최적화

**임베딩 캐싱** (의미 기반 유사도 사용 시)
- 메모리: 최근 N개 텍스트의 벡터
- Redis: 자주 조회되는 벡터
- 주의: 메모리 사용량 고려 (벡터 크기 × 개수)

**배치 처리**
- 여러 메시지를 묶어서 처리
- DB 쿼리 횟수 감소
- 임베딩 계산 배치화 (GPU 활용 시 효율적)
- 유사도 계산 배치 수행

**비동기 처리**
- 유사도 계산을 별도 워커로 분리
- 빠른 판정은 즉시, 느린 계산은 비동기

---

## 8. 기술 선택 시 고려사항

### 8.1 유사도 계산

**단순 방법 (Token-based)**
- 라이브러리: NLTK, spaCy
- 장점: 빠름, 이해하기 쉬움
- 단점: 정확도 제한

**임베딩 기반**
- 모델: Sentence-BERT, USE (Universal Sentence Encoder)
- 장점: 높은 정확도
- 단점: 느림, 리소스 많이 필요

**선택 가이드**:
- 초기: Token-based로 시작
- 정확도 필요시: 임베딩 추가
- 하이브리드: 두 방법 조합

### 8.2 데이터베이스

**PostgreSQL**
- 장점: 범용적, 안정적, 전문 검색
- 단점: 쓰기 부하 시 성능
- 추천: 대부분의 경우

**Elasticsearch**
- 장점: 빠른 검색, 유사도 검색 내장
- 단점: 운영 복잡도
- 추천: 검색 기능이 중요한 경우

**MongoDB**
- 장점: 유연한 스키마, 빠른 쓰기
- 단점: 일관성 제한
- 추천: 단순 저장이 주목적

---

## 9. 중복 이력 기반 인용 지수 활용 (향후 확장)

### 9.1 개념

중복 데이터에 원본 ID를 기록하여, 나중에 "인용 지수"처럼 활용 가능합니다.

```
논문 인용 지수:
  많이 인용된 논문 = 중요한 논문

발언 인용 지수:
  많이 중복된 발언 = 여러 채널에서 보도 = 중요한 발언
```

### 9.2 기본 구조

**중복 이력 테이블:**
```
dedup_history:
  - duplicate_id (중복된 데이터 ID)
  - original_id (최초 데이터 ID) ⭐
  - channel, similarity, detected_at
```

**인용 지수 계산:**
```sql
SELECT COUNT(*) as citation_count
FROM dedup_history
WHERE original_id = 'data_123'

결과: 4 → 4개 채널에서 중복 보도
```

### 9.3 활용 예시 (MVP 이후)

1. **피드 표시**: "🔥 5개 채널에서 보도"
2. **중요도 점수**: citation_count로 가중치 부여
3. **푸시 알림**: 3개 이상 중복 시 알림
4. **통계**: 가장 많이 보도된 발언 TOP 10

### 9.4 장점

- 원본 데이터 변경 불필요 (단순함)
- 유연한 집계 (다양한 쿼리 가능)
- 원본 삭제되어도 참조 유지

**참고**: MVP에서는 중복 이력만 기록하고, 인용 지수 활용은 이후 단계에서 구현

---

## 부록: 용어 정의

| 용어 | 설명 |
|------|------|
| **Similarity Detector** | 텍스트 유사도를 계산하는 컴포넌트 |
| **Decision Handler** | 중복 판정 결과에 따라 처리 행동을 결정하는 컴포넌트 |
| **Dedup History** | 중복으로 판정된 데이터의 이력 저장소 |
| **Time Window** | 중복 체크를 수행할 시간 범위 |
| **Similarity Threshold** | 중복으로 판정하는 유사도 기준값 |
| **False Positive** | 중복이 아닌데 중복으로 잘못 판정 |
| **False Negative** | 중복인데 중복이 아니라고 잘못 판정 |
| **Citation Count** | 특정 발언이 중복된 횟수 (인용 지수) |

---

**문서 끝**